{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FILTER 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add custom concatenation of txt files controlled by some config to avoid saturation of topics\n",
    "# this is temporary\n",
    "TEXT_FILE_PATH = '/home/penguin/GeorgianWritingWizard/data/whole_corpus/georgian_large_corpus_v2.txt'\n",
    "OUT_TEXT_FILE_PATH = '/home/penguin/GeorgianWritingWizard/data/whole_corpus/filter_v0/filtered.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TEXT_FILE_PATH, 'r', encoding='utf-8') as f, \\\n",
    "     open(OUT_TEXT_FILE_PATH, 'w', encoding='utf-8') as out:\n",
    "    for line in f:\n",
    "        possible_line = re.sub(r'[\\u0041-\\u005A\\u0061-\\u007A\\u4E00-\\u9FFF\\u0400-\\u04FF]+|\\s+', ' ', line).strip()\n",
    "        possible_line = re.sub(emoji_pattern, '', possible_line)\n",
    "\n",
    "        if len(possible_line.strip().split()) < 15:\n",
    "            continue\n",
    "        out.write(unicodedata.normalize(\"NFKD\", possible_line.strip()) + '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_FILE_PATH = '/home/penguin/GeorgianWritingWizard/data/whole_corpus/filter_v0/filtered.txt'\n",
    "OUT_TEXT_FILE_PATH = '/home/penguin/GeorgianWritingWizard/data/whole_corpus/filter_v1/filtered.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8640776699029126"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_ok(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "charset =''.join([chr(i) for i in range(4304, 4304 + 33)])\n",
    "charset += ' -,._!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_ok(line):\n",
    "    geo_chars_count = 0\n",
    "    for ch in line:\n",
    "        if ch in charset:\n",
    "            geo_chars_count += 1\n",
    "\n",
    "    return geo_chars_count / len(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line.spl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TEXT_FILE_PATH, 'r', encoding='utf-8') as f, open(OUT_TEXT_FILE_PATH, 'w', encoding='utf-8') as out:\n",
    "    for line in f:\n",
    "        if is_ok(line) > 0.75:\n",
    "            out.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('/home/penguin/GeorgianWritingWizard/language_engine/examples/outputs/2023-03-16/13-42-35/tokenizer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = dict(sorted(a.items(), key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_tokens = list(tokenizer.special_tokens_map.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_chas = []\n",
    "\n",
    "for key, val in ns.items():\n",
    "    if val < 1363:\n",
    "        if key not in charset and key not in sp_tokens and key not in [str(i) for i in range(1, 10)]:\n",
    "            bad_chas.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1309"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bad_chas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_FILE_PATH = '/home/penguin/GeorgianWritingWizard/data/whole_corpus/filter_v1/filtered.txt'\n",
    "OUT_TEXT_FILE_PATH = '/home/penguin/GeorgianWritingWizard/data/whole_corpus/filter_v2/filtered.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_chars(input_str, chars_to_remove):\n",
    "    pattern = \"[\" + re.escape(\"\".join(chars_to_remove)) + \"]\"\n",
    "    return re.sub(pattern, \"\", input_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TEXT_FILE_PATH, 'r', encoding='utf-8') as f,\\\n",
    "     open(OUT_TEXT_FILE_PATH, 'w', encoding='utf-8') as out:\n",
    "    \n",
    "    for line in f:\n",
    "        n_line = remove_chars(line, bad_chas)\n",
    "        out.write(n_line)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penguin/miniconda3/envs/research/lib/python3.8/site-packages/datasets/arrow_dataset.py:1533: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ds = load_from_disk('/home/penguin/GeorgianWritingWizard/language_engine/examples/processed_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264d343de3414bbdacdc3061c8630caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds.push_to_hub('ZurabDz/tokenized_large_corpus', token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask'],\n",
       "    num_rows: 5521515\n",
       "})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
